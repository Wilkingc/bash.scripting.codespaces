{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d8435cc-ed5a-486f-a5b2-8d016992a25a",
   "metadata": {},
   "source": [
    "# Creating a data-only Docker image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e3b468-6f55-486f-ab43-8659f8959349",
   "metadata": {},
   "source": [
    "## Setup \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "272a8f45-17de-4b30-8101-7243593d3b82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+ mkdir -p data\n",
      "+ tree\n",
      ".\n",
      "├── Dockerfile\n",
      "├── data\n",
      "├── data_01\n",
      "│   ├── a-z.01-1k.tsv\n",
      "│   ├── a-z.combined.tsv\n",
      "│   └── titanic.csv\n",
      "├── data_01.tar\n",
      "└── image.data-only.ipynb\n",
      "\n",
      "2 directories, 6 files\n"
     ]
    }
   ],
   "source": [
    "set -x\n",
    "mkdir -p data\n",
    "tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "570a53fa-89c5-4c2d-adfe-1e5a8af79633",
   "metadata": {},
   "source": [
    "## Get data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2decd4dc-1f56-4df5-b1b0-e17476dac768",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+ cd data\n",
      "+ curl -L -s -o titanic.csv https://ddc-datascience.s3.amazonaws.com/Projects/Example/Data/Titanic.train.csv\n",
      "+ curl -L -s -o a-z.01-1k.tsv https://ddc-datascience.s3.amazonaws.com/a-z.business/2023-08-21/01.1k.txt\n",
      "+ curl -L -s -o a-z.combined.tsv https://ddc-datascience.s3.amazonaws.com/a-z.business/2023-08-21/combined.txt\n"
     ]
    }
   ],
   "source": [
    "(\n",
    "cd data\n",
    "curl -L -s -o titanic.csv 'https://ddc-datascience.s3.amazonaws.com/Projects/Example/Data/Titanic.train.csv'\n",
    "curl -L -s -o a-z.01-1k.tsv 'https://ddc-datascience.s3.amazonaws.com/a-z.business/2023-08-21/01.1k.txt'\n",
    "curl -L -s -o a-z.combined.tsv 'https://ddc-datascience.s3.amazonaws.com/a-z.business/2023-08-21/combined.txt'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38d7c3d4-a2d6-4585-b388-4e86daa12dc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+ tree\n",
      ".\n",
      "├── Dockerfile\n",
      "├── data\n",
      "│   ├── a-z.01-1k.tsv\n",
      "│   ├── a-z.combined.tsv\n",
      "│   └── titanic.csv\n",
      "├── data_01\n",
      "│   ├── a-z.01-1k.tsv\n",
      "│   ├── a-z.combined.tsv\n",
      "│   └── titanic.csv\n",
      "├── data_01.tar\n",
      "└── image.data-only.ipynb\n",
      "\n",
      "2 directories, 9 files\n"
     ]
    }
   ],
   "source": [
    "tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6adff33-968d-4c7c-ba20-48220d9cb9f2",
   "metadata": {},
   "source": [
    "## From a folder tar file\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c6f15f-4e3a-43b0-ae17-d666986645e5",
   "metadata": {},
   "source": [
    "### Create tar file from folder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ceb7016f-9db8-43b2-9939-cdfcb1412e74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+ tar -cvf data_01.tar data\n",
      "data/\n",
      "data/titanic.csv\n",
      "data/a-z.01-1k.tsv\n",
      "data/a-z.combined.tsv\n"
     ]
    }
   ],
   "source": [
    "tar -cvf data_01.tar data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "21ccafa1-aafc-4867-ad88-80be80435777",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+ mv data data_01\n",
      "+ tree\n",
      ".\n",
      "├── Dockerfile\n",
      "├── data_01\n",
      "│   ├── a-z.01-1k.tsv\n",
      "│   ├── a-z.combined.tsv\n",
      "│   ├── data\n",
      "│   │   ├── a-z.01-1k.tsv\n",
      "│   │   ├── a-z.combined.tsv\n",
      "│   │   └── titanic.csv\n",
      "│   └── titanic.csv\n",
      "├── data_01.tar\n",
      "└── image.data-only.ipynb\n",
      "\n",
      "2 directories, 9 files\n"
     ]
    }
   ],
   "source": [
    "mv data data_01\n",
    "tree\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f71539-8922-4f64-8be6-d850f14d1b3b",
   "metadata": {},
   "source": [
    "### Create image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "52087a9e-528e-43b8-8df0-f2e998f509a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+ docker image import data_01.tar data:01\n",
      "sha256:412389b22d70bc6c0f8b55c4bdb5cd0440517960db72f0ffced43974e224f8ba\n",
      "+ docker image list -a\n",
      "+ grep --color=auto data\n",
      "data                    01        412389b22d70   Less than a second ago   39.2MB\n"
     ]
    }
   ],
   "source": [
    "docker image import data_01.tar data:01\n",
    "docker image list -a | grep data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fe12b2f-1b8a-4c38-b1ca-68a83b40cdbc",
   "metadata": {},
   "source": [
    "### Create volume from instance from image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0de42e99-7f0b-40d4-98ba-b0c6b842470f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+ docker container create --volume data_01:/data --name data_01 data:01 :\n",
      "5e343f54899fb0b2ade30aa085a28247465ec7282db60a5e514d516f3d9d7dbb\n",
      "+ grep --color=auto data\n",
      "+ docker container list -a\n",
      "5e343f54899f   data:01                 \":\"                      4 seconds ago   Created                                  data_01\n",
      "+ docker volume list\n",
      "DRIVER    VOLUME NAME\n",
      "local     data_01\n"
     ]
    }
   ],
   "source": [
    "docker container create --volume data_01:/data --name data_01 data:01 :\n",
    "docker container list -a | grep data\n",
    "docker volume list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d89a588d-3e31-4426-9aab-4e1e15b93c75",
   "metadata": {},
   "source": [
    "### Show data in volume\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c417f2f3-202b-47aa-8653-974efd35f16b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+ docker container run --volume data_01:/data --rm -it ubuntu ls -lA / /data\n",
      "/:\n",
      "total 24\n",
      "-rwxr-xr-x   1 root   root      0 Mar 20 14:11 .dockerenv\n",
      "lrwxrwxrwx   1 root   root      7 Feb 27 15:59 bin -> usr/bin\n",
      "drwxr-xr-x   1 root   root      0 Apr 18  2022 boot\n",
      "drwxr-xr-x   1 root   root     80 Mar 20 14:11 data\n",
      "drwxr-xr-x   5 root   root    360 Mar 20 14:11 dev\n",
      "drwxr-xr-x   1 root   root     56 Mar 20 14:11 etc\n",
      "drwxr-xr-x   1 root   root      0 Apr 18  2022 home\n",
      "lrwxrwxrwx   1 root   root      7 Feb 27 15:59 lib -> usr/lib\n",
      "lrwxrwxrwx   1 root   root      9 Feb 27 15:59 lib32 -> usr/lib32\n",
      "lrwxrwxrwx   1 root   root      9 Feb 27 15:59 lib64 -> usr/lib64\n",
      "lrwxrwxrwx   1 root   root     10 Feb 27 15:59 libx32 -> usr/libx32\n",
      "drwxr-xr-x   1 root   root      0 Feb 27 15:59 media\n",
      "drwxr-xr-x   1 root   root      0 Feb 27 15:59 mnt\n",
      "drwxr-xr-x   1 root   root      0 Feb 27 15:59 opt\n",
      "dr-xr-xr-x 201 nobody nogroup   0 Mar 20 14:11 proc\n",
      "drwx------   1 root   root     30 Feb 27 16:02 root\n",
      "drwxr-xr-x   1 root   root     32 Feb 27 16:03 run\n",
      "lrwxrwxrwx   1 root   root      8 Feb 27 15:59 sbin -> usr/sbin\n",
      "drwxr-xr-x   1 root   root      0 Feb 27 15:59 srv\n",
      "dr-xr-xr-x  12 nobody nogroup   0 Mar 20 14:11 sys\n",
      "drwxrwxrwt   1 root   root      0 Feb 27 16:02 tmp\n",
      "drwxr-xr-x   1 root   root    116 Feb 27 15:59 usr\n",
      "drwxr-xr-x   1 root   root     90 Feb 27 16:02 var\n",
      "\n",
      "/data:\n",
      "total 38292\n",
      "-rw-r--r-- 1 root root  1006550 Mar 20 14:10 a-z.01-1k.tsv\n",
      "-rw-r--r-- 1 root root 38138507 Mar 20 14:11 a-z.combined.tsv\n",
      "-rw-r--r-- 1 root root    61194 Mar 20 14:10 titanic.csv\n"
     ]
    }
   ],
   "source": [
    "docker container run --volume data_01:/data --rm -it ubuntu ls -lA / /data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e92c4079-0907-4dc3-8684-dd44d395fa4c",
   "metadata": {},
   "source": [
    "## From instance tar file\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c92da6-29e0-4094-b0b2-c889ae28198e",
   "metadata": {},
   "source": [
    "### Create tar file from instance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8318dcab-ecd0-43ef-9158-252060e5b7eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+ docker container export data_01\n",
      "+ tar -tvf data_02.tar\n",
      "-rwxr-xr-x 0/0               0 2024-03-20 14:11 .dockerenv\n",
      "drwxr-xr-x 0/0               0 2024-03-20 14:10 data/\n",
      "-rw-r--r-- 0/0         1006550 2024-03-20 14:10 data/a-z.01-1k.tsv\n",
      "-rw-r--r-- 0/0        38138507 2024-03-20 14:11 data/a-z.combined.tsv\n",
      "-rw-r--r-- 0/0           61194 2024-03-20 14:10 data/titanic.csv\n",
      "drwxr-xr-x 0/0               0 2024-03-20 14:11 dev/\n",
      "-rwxr-xr-x 0/0               0 2024-03-20 14:11 dev/console\n",
      "drwxr-xr-x 0/0               0 2024-03-20 14:11 dev/pts/\n",
      "drwxr-xr-x 0/0               0 2024-03-20 14:11 dev/shm/\n",
      "drwxr-xr-x 0/0               0 2024-03-20 14:11 etc/\n",
      "-rwxr-xr-x 0/0               0 2024-03-20 14:11 etc/hostname\n",
      "-rwxr-xr-x 0/0               0 2024-03-20 14:11 etc/hosts\n",
      "lrwxrwxrwx 0/0               0 2024-03-20 14:11 etc/mtab -> /proc/mounts\n",
      "-rwxr-xr-x 0/0               0 2024-03-20 14:11 etc/resolv.conf\n",
      "drwxr-xr-x 0/0               0 2024-03-20 14:11 proc/\n",
      "drwxr-xr-x 0/0               0 2024-03-20 14:11 sys/\n",
      "+ tar -tvf data_02.tar data/\n",
      "drwxr-xr-x 0/0               0 2024-03-20 14:10 data/\n",
      "-rw-r--r-- 0/0         1006550 2024-03-20 14:10 data/a-z.01-1k.tsv\n",
      "-rw-r--r-- 0/0        38138507 2024-03-20 14:11 data/a-z.combined.tsv\n",
      "-rw-r--r-- 0/0           61194 2024-03-20 14:10 data/titanic.csv\n"
     ]
    }
   ],
   "source": [
    "docker container export data_01 > data_02.tar\n",
    "tar -tvf data_02.tar\n",
    "tar -tvf data_02.tar data/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf6be394-b788-495d-81d7-0d90892e08b7",
   "metadata": {},
   "source": [
    "### Create image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "749fc311-7808-4844-bd07-4583cd1441d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+ docker image import data_02.tar data:02\n",
      "sha256:22a85a7ce44857c550408e22ba0d4cd2b855e59f6883783931390b8862858a67\n",
      "+ grep --color=auto data\n",
      "+ docker image list -a\n",
      "data                    02        22a85a7ce448   Less than a second ago   39.2MB\n",
      "data                    01        412389b22d70   10 seconds ago           39.2MB\n"
     ]
    }
   ],
   "source": [
    "docker image import data_02.tar data:02\n",
    "docker image list -a | grep data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "802d5622-7743-4d30-a657-2b3a16fa2b49",
   "metadata": {},
   "source": [
    "### Create volume from instance from image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "294c6585-ff15-4353-a8b2-533b8c7cc398",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+ docker container create --volume data_02:/data --name data_02 data:02 :\n",
      "dd96c2430435bdb782bb6a583a3e316b7edb794d527c23f0c615775fb7a88e67\n",
      "+ grep --color=auto data\n",
      "+ docker container list -a\n",
      "dd96c2430435   data:02                 \":\"                      2 seconds ago    Created                                  data_02\n",
      "5e343f54899f   data:01                 \":\"                      12 seconds ago   Created                                  data_01\n",
      "+ docker volume list\n",
      "DRIVER    VOLUME NAME\n",
      "local     data_01\n",
      "local     data_02\n"
     ]
    }
   ],
   "source": [
    "docker container create --volume data_02:/data --name data_02 data:02 :\n",
    "docker container list -a | grep data\n",
    "docker volume list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fbf06e6-1553-462e-a578-cc544930731d",
   "metadata": {},
   "source": [
    "### Show data in volume\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "020cfdc0-5e5f-4944-86c8-6bee3ddcd5be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+ docker container run --volume data_02:/data --rm -it ubuntu ls -lA / /data\n",
      "/:\n",
      "total 24\n",
      "-rwxr-xr-x   1 root   root      0 Mar 20 14:11 .dockerenv\n",
      "lrwxrwxrwx   1 root   root      7 Feb 27 15:59 bin -> usr/bin\n",
      "drwxr-xr-x   1 root   root      0 Apr 18  2022 boot\n",
      "drwxr-xr-x   1 root   root     80 Mar 20 14:11 data\n",
      "drwxr-xr-x   5 root   root    360 Mar 20 14:11 dev\n",
      "drwxr-xr-x   1 root   root     56 Mar 20 14:11 etc\n",
      "drwxr-xr-x   1 root   root      0 Apr 18  2022 home\n",
      "lrwxrwxrwx   1 root   root      7 Feb 27 15:59 lib -> usr/lib\n",
      "lrwxrwxrwx   1 root   root      9 Feb 27 15:59 lib32 -> usr/lib32\n",
      "lrwxrwxrwx   1 root   root      9 Feb 27 15:59 lib64 -> usr/lib64\n",
      "lrwxrwxrwx   1 root   root     10 Feb 27 15:59 libx32 -> usr/libx32\n",
      "drwxr-xr-x   1 root   root      0 Feb 27 15:59 media\n",
      "drwxr-xr-x   1 root   root      0 Feb 27 15:59 mnt\n",
      "drwxr-xr-x   1 root   root      0 Feb 27 15:59 opt\n",
      "dr-xr-xr-x 201 nobody nogroup   0 Mar 20 14:11 proc\n",
      "drwx------   1 root   root     30 Feb 27 16:02 root\n",
      "drwxr-xr-x   1 root   root     32 Feb 27 16:03 run\n",
      "lrwxrwxrwx   1 root   root      8 Feb 27 15:59 sbin -> usr/sbin\n",
      "drwxr-xr-x   1 root   root      0 Feb 27 15:59 srv\n",
      "dr-xr-xr-x  12 nobody nogroup   0 Mar 20 14:11 sys\n",
      "drwxrwxrwt   1 root   root      0 Feb 27 16:02 tmp\n",
      "drwxr-xr-x   1 root   root    116 Feb 27 15:59 usr\n",
      "drwxr-xr-x   1 root   root     90 Feb 27 16:02 var\n",
      "\n",
      "/data:\n",
      "total 38292\n",
      "-rw-r--r-- 1 root root  1006550 Mar 20 14:10 a-z.01-1k.tsv\n",
      "-rw-r--r-- 1 root root 38138507 Mar 20 14:11 a-z.combined.tsv\n",
      "-rw-r--r-- 1 root root    61194 Mar 20 14:10 titanic.csv\n"
     ]
    }
   ],
   "source": [
    "docker container run --volume data_02:/data --rm -it ubuntu ls -lA / /data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c599a39d-ac89-4dc8-9cdd-3b3c2c087f57",
   "metadata": {},
   "source": [
    "## From a Dockerfile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d71f69-faa0-452d-8d55-e1b46ff2cc0e",
   "metadata": {},
   "source": [
    "### Create image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b30b16b2-2383-4fc3-b3c7-1f2ef504f104",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+ docker image build --tag csv_datasets ./.\n",
      "\u001b[1A\u001b[1B\u001b[0G\u001b[?25l[+] Building 0.0s (0/0)  docker:default\n",
      "\u001b[?25h\u001b[1A\u001b[0G\u001b[?25l[+] Building 0.0s (0/1)                                          docker:default\n",
      "\u001b[?25h\u001b[1A\u001b[0G\u001b[?25l[+] Building 0.1s (2/3)                                          docker:default\n",
      "\u001b[34m => [internal] load build definition from Dockerfile                       0.1s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 731B                                       0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/library/ubuntu:22.04            0.0s\n",
      "\u001b[0m => [internal] load .dockerignore                                          0.0s\n",
      " => => transferring context:                                               0.0s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 0.2s (3/6)                                          docker:default\n",
      "\u001b[34m => [internal] load build definition from Dockerfile                       0.1s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 731B                                       0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/library/ubuntu:22.04            0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.1s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 0.3s (13/13)                                        docker:default\n",
      "\u001b[34m => [internal] load build definition from Dockerfile                       0.1s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 731B                                       0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/library/ubuntu:22.04            0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.1s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [data 1/6] FROM docker.io/library/ubuntu:22.04                         0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.1s\n",
      "\u001b[0m\u001b[34m => => transferring context: 32B                                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [data 2/6] RUN apt-get update && apt-get install -y curl        0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [data 3/6] WORKDIR /data                                        0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [data 4/6] RUN curl -L -s -o titanic.csv 'https://ddc-datascie  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [data 5/6] RUN curl -L -s -o a-z.01-1k.tsv 'https://ddc-datasc  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [data 6/6] RUN curl -L -s -o a-z.combined.tsv 'https://ddc-dat  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [stage-1 1/2] COPY --from=data /data /data                      0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [stage-1 2/2] COPY Dockerfile /                                 0.0s\n",
      "\u001b[0m\u001b[34m => exporting to image                                                     0.0s\n",
      "\u001b[0m\u001b[34m => => exporting layers                                                    0.0s\n",
      "\u001b[0m\u001b[34m => => writing image sha256:aacbedf068395216287006b4374abcb586752fdcffe99  0.0s\n",
      "\u001b[0m\u001b[34m => => naming to docker.io/library/csv_datasets                            0.0s\n",
      "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 0.5s (13/13)                                        docker:default\n",
      "\u001b[34m => [internal] load build definition from Dockerfile                       0.1s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 731B                                       0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/library/ubuntu:22.04            0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.1s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [data 1/6] FROM docker.io/library/ubuntu:22.04                         0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.1s\n",
      "\u001b[0m\u001b[34m => => transferring context: 32B                                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [data 2/6] RUN apt-get update && apt-get install -y curl        0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [data 3/6] WORKDIR /data                                        0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [data 4/6] RUN curl -L -s -o titanic.csv 'https://ddc-datascie  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [data 5/6] RUN curl -L -s -o a-z.01-1k.tsv 'https://ddc-datasc  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [data 6/6] RUN curl -L -s -o a-z.combined.tsv 'https://ddc-dat  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [stage-1 1/2] COPY --from=data /data /data                      0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [stage-1 2/2] COPY Dockerfile /                                 0.0s\n",
      "\u001b[0m\u001b[34m => exporting to image                                                     0.0s\n",
      "\u001b[0m\u001b[34m => => exporting layers                                                    0.0s\n",
      "\u001b[0m\u001b[34m => => writing image sha256:aacbedf068395216287006b4374abcb586752fdcffe99  0.0s\n",
      "\u001b[0m\u001b[34m => => naming to docker.io/library/csv_datasets                            0.0s\n",
      "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 0.6s (13/13)                                        docker:default\n",
      "\u001b[34m => [internal] load build definition from Dockerfile                       0.1s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 731B                                       0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/library/ubuntu:22.04            0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.1s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [data 1/6] FROM docker.io/library/ubuntu:22.04                         0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.1s\n",
      "\u001b[0m\u001b[34m => => transferring context: 32B                                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [data 2/6] RUN apt-get update && apt-get install -y curl        0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [data 3/6] WORKDIR /data                                        0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [data 4/6] RUN curl -L -s -o titanic.csv 'https://ddc-datascie  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [data 5/6] RUN curl -L -s -o a-z.01-1k.tsv 'https://ddc-datasc  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [data 6/6] RUN curl -L -s -o a-z.combined.tsv 'https://ddc-dat  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [stage-1 1/2] COPY --from=data /data /data                      0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [stage-1 2/2] COPY Dockerfile /                                 0.0s\n",
      "\u001b[0m\u001b[34m => exporting to image                                                     0.0s\n",
      "\u001b[0m\u001b[34m => => exporting layers                                                    0.0s\n",
      "\u001b[0m\u001b[34m => => writing image sha256:aacbedf068395216287006b4374abcb586752fdcffe99  0.0s\n",
      "\u001b[0m\u001b[34m => => naming to docker.io/library/csv_datasets                            0.0s\n",
      "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 0.8s (13/13)                                        docker:default\n",
      "\u001b[34m => [internal] load build definition from Dockerfile                       0.1s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 731B                                       0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/library/ubuntu:22.04            0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.1s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [data 1/6] FROM docker.io/library/ubuntu:22.04                         0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.1s\n",
      "\u001b[0m\u001b[34m => => transferring context: 32B                                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [data 2/6] RUN apt-get update && apt-get install -y curl        0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [data 3/6] WORKDIR /data                                        0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [data 4/6] RUN curl -L -s -o titanic.csv 'https://ddc-datascie  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [data 5/6] RUN curl -L -s -o a-z.01-1k.tsv 'https://ddc-datasc  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [data 6/6] RUN curl -L -s -o a-z.combined.tsv 'https://ddc-dat  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [stage-1 1/2] COPY --from=data /data /data                      0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [stage-1 2/2] COPY Dockerfile /                                 0.0s\n",
      "\u001b[0m\u001b[34m => exporting to image                                                     0.0s\n",
      "\u001b[0m\u001b[34m => => exporting layers                                                    0.0s\n",
      "\u001b[0m\u001b[34m => => writing image sha256:aacbedf068395216287006b4374abcb586752fdcffe99  0.0s\n",
      "\u001b[0m\u001b[34m => => naming to docker.io/library/csv_datasets                            0.0s\n",
      "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 0.9s (13/13)                                        docker:default\n",
      "\u001b[34m => [internal] load build definition from Dockerfile                       0.1s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 731B                                       0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/library/ubuntu:22.04            0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.1s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [data 1/6] FROM docker.io/library/ubuntu:22.04                         0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.1s\n",
      "\u001b[0m\u001b[34m => => transferring context: 32B                                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [data 2/6] RUN apt-get update && apt-get install -y curl        0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [data 3/6] WORKDIR /data                                        0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [data 4/6] RUN curl -L -s -o titanic.csv 'https://ddc-datascie  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [data 5/6] RUN curl -L -s -o a-z.01-1k.tsv 'https://ddc-datasc  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [data 6/6] RUN curl -L -s -o a-z.combined.tsv 'https://ddc-dat  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [stage-1 1/2] COPY --from=data /data /data                      0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [stage-1 2/2] COPY Dockerfile /                                 0.0s\n",
      "\u001b[0m\u001b[34m => exporting to image                                                     0.0s\n",
      "\u001b[0m\u001b[34m => => exporting layers                                                    0.0s\n",
      "\u001b[0m\u001b[34m => => writing image sha256:aacbedf068395216287006b4374abcb586752fdcffe99  0.0s\n",
      "\u001b[0m\u001b[34m => => naming to docker.io/library/csv_datasets                            0.0s\n",
      "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 1.1s (13/13)                                        docker:default\n",
      "\u001b[34m => [internal] load build definition from Dockerfile                       0.1s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 731B                                       0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/library/ubuntu:22.04            0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.1s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [data 1/6] FROM docker.io/library/ubuntu:22.04                         0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.1s\n",
      "\u001b[0m\u001b[34m => => transferring context: 32B                                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [data 2/6] RUN apt-get update && apt-get install -y curl        0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [data 3/6] WORKDIR /data                                        0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [data 4/6] RUN curl -L -s -o titanic.csv 'https://ddc-datascie  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [data 5/6] RUN curl -L -s -o a-z.01-1k.tsv 'https://ddc-datasc  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [data 6/6] RUN curl -L -s -o a-z.combined.tsv 'https://ddc-dat  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [stage-1 1/2] COPY --from=data /data /data                      0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [stage-1 2/2] COPY Dockerfile /                                 0.0s\n",
      "\u001b[0m\u001b[34m => exporting to image                                                     0.0s\n",
      "\u001b[0m\u001b[34m => => exporting layers                                                    0.0s\n",
      "\u001b[0m\u001b[34m => => writing image sha256:aacbedf068395216287006b4374abcb586752fdcffe99  0.0s\n",
      "\u001b[0m\u001b[34m => => naming to docker.io/library/csv_datasets                            0.0s\n",
      "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 1.2s (13/13) FINISHED                               docker:default\n",
      "\u001b[34m => [internal] load build definition from Dockerfile                       0.1s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 731B                                       0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/library/ubuntu:22.04            0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.1s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [data 1/6] FROM docker.io/library/ubuntu:22.04                         0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.1s\n",
      "\u001b[0m\u001b[34m => => transferring context: 32B                                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [data 2/6] RUN apt-get update && apt-get install -y curl        0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [data 3/6] WORKDIR /data                                        0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [data 4/6] RUN curl -L -s -o titanic.csv 'https://ddc-datascie  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [data 5/6] RUN curl -L -s -o a-z.01-1k.tsv 'https://ddc-datasc  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [data 6/6] RUN curl -L -s -o a-z.combined.tsv 'https://ddc-dat  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [stage-1 1/2] COPY --from=data /data /data                      0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [stage-1 2/2] COPY Dockerfile /                                 0.0s\n",
      "\u001b[0m\u001b[34m => exporting to image                                                     0.0s\n",
      "\u001b[0m\u001b[34m => => exporting layers                                                    0.0s\n",
      "\u001b[0m\u001b[34m => => writing image sha256:aacbedf068395216287006b4374abcb586752fdcffe99  0.0s\n",
      "\u001b[0m\u001b[34m => => naming to docker.io/library/csv_datasets                            0.0s\n",
      "\u001b[0m\u001b[?25h\n",
      "+ grep --color=auto data\n",
      "+ docker image list -a\n",
      "data                    02        22a85a7ce448   6 seconds ago    39.2MB\n",
      "data                    01        412389b22d70   16 seconds ago   39.2MB\n",
      "csv_datasets            latest    aacbedf06839   25 hours ago     39.2MB\n"
     ]
    }
   ],
   "source": [
    "docker image build --tag csv_datasets ./.\n",
    "docker image list -a | grep data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c954ce2-6aeb-42a8-9625-21851f2d16ca",
   "metadata": {},
   "source": [
    "### Create volume from instance from image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a6253e92-017d-4809-881a-1c1e7780b86a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+ docker container create --volume data_03:/data --name data_03 csv_datasets :\n",
      "3572673334e75b49125a90aa15b99f268156b4a0df5bfadb6cf97f132188f302\n",
      "+ grep --color=auto data\n",
      "+ docker container list -a\n",
      "3572673334e7   csv_datasets            \":\"                      1 second ago     Created                                  data_03\n",
      "dd96c2430435   data:02                 \":\"                      7 seconds ago    Created                                  data_02\n",
      "5e343f54899f   data:01                 \":\"                      17 seconds ago   Created                                  data_01\n",
      "+ docker volume list\n",
      "DRIVER    VOLUME NAME\n",
      "local     data_01\n",
      "local     data_02\n",
      "local     data_03\n"
     ]
    }
   ],
   "source": [
    "docker container create --volume data_03:/data --name data_03 csv_datasets :\n",
    "docker container list -a | grep data\n",
    "docker volume list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec1962c-9481-4995-b321-25a7046827b2",
   "metadata": {},
   "source": [
    "### Show data in volume\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3d16b8d8-7124-49e3-9895-2252ebb4dd20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+ docker container run --volume data_03:/data --rm -it ubuntu ls -lA / /data\n",
      "/:\n",
      "total 24\n",
      "-rwxr-xr-x   1 root   root      0 Mar 20 14:11 .dockerenv\n",
      "lrwxrwxrwx   1 root   root      7 Feb 27 15:59 bin -> usr/bin\n",
      "drwxr-xr-x   1 root   root      0 Apr 18  2022 boot\n",
      "drwxr-xr-x   1 root   root     80 Mar 20 14:11 data\n",
      "drwxr-xr-x   5 root   root    360 Mar 20 14:11 dev\n",
      "drwxr-xr-x   1 root   root     56 Mar 20 14:11 etc\n",
      "drwxr-xr-x   1 root   root      0 Apr 18  2022 home\n",
      "lrwxrwxrwx   1 root   root      7 Feb 27 15:59 lib -> usr/lib\n",
      "lrwxrwxrwx   1 root   root      9 Feb 27 15:59 lib32 -> usr/lib32\n",
      "lrwxrwxrwx   1 root   root      9 Feb 27 15:59 lib64 -> usr/lib64\n",
      "lrwxrwxrwx   1 root   root     10 Feb 27 15:59 libx32 -> usr/libx32\n",
      "drwxr-xr-x   1 root   root      0 Feb 27 15:59 media\n",
      "drwxr-xr-x   1 root   root      0 Feb 27 15:59 mnt\n",
      "drwxr-xr-x   1 root   root      0 Feb 27 15:59 opt\n",
      "dr-xr-xr-x 202 nobody nogroup   0 Mar 20 14:11 proc\n",
      "drwx------   1 root   root     30 Feb 27 16:02 root\n",
      "drwxr-xr-x   1 root   root     32 Feb 27 16:03 run\n",
      "lrwxrwxrwx   1 root   root      8 Feb 27 15:59 sbin -> usr/sbin\n",
      "drwxr-xr-x   1 root   root      0 Feb 27 15:59 srv\n",
      "dr-xr-xr-x  12 nobody nogroup   0 Mar 20 14:11 sys\n",
      "drwxrwxrwt   1 root   root      0 Feb 27 16:02 tmp\n",
      "drwxr-xr-x   1 root   root    116 Feb 27 15:59 usr\n",
      "drwxr-xr-x   1 root   root     90 Feb 27 16:02 var\n",
      "\n",
      "/data:\n",
      "total 38292\n",
      "-rw-r--r-- 1 root root  1006550 Mar 19 12:55 a-z.01-1k.tsv\n",
      "-rw-r--r-- 1 root root 38138507 Mar 19 12:56 a-z.combined.tsv\n",
      "-rw-r--r-- 1 root root    61194 Mar 19 12:55 titanic.csv\n"
     ]
    }
   ],
   "source": [
    "docker container run --volume data_03:/data --rm -it ubuntu ls -lA / /data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f21d54-f1d1-4ab3-add9-07065379cd58",
   "metadata": {},
   "source": [
    "## Clean up\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9a8abd29-b617-418a-abed-090cfce8688e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+ docker container rm data_01 data_02 data_03\n",
      "data_01\n",
      "data_02\n",
      "data_03\n",
      "+ docker volume rm data_01 data_02 data_03\n",
      "data_01\n",
      "data_02\n",
      "data_03\n",
      "+ docker image rm data:01 data:02 csv_datasets\n",
      "Untagged: data:01\n",
      "Deleted: sha256:412389b22d70bc6c0f8b55c4bdb5cd0440517960db72f0ffced43974e224f8ba\n",
      "Untagged: data:02\n",
      "Deleted: sha256:22a85a7ce44857c550408e22ba0d4cd2b855e59f6883783931390b8862858a67\n",
      "Deleted: sha256:32ae24d5dccc3ee34db3341a896cf769db1cb0eafb0e37fd1d36679f603ecc27\n",
      "Untagged: csv_datasets:latest\n",
      "Deleted: sha256:aacbedf068395216287006b4374abcb586752fdcffe9986bf2da53dc3b4f4a8e\n",
      "+ rm -rf data_01 data_01.tar data_02.tar\n"
     ]
    }
   ],
   "source": [
    "docker container rm data_01 data_02  data_03\n",
    "docker volume rm data_01 data_02 data_03 \n",
    "docker image rm data:01 data:02 csv_datasets\n",
    "rm -rf data*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d62531-0451-4916-adda-809542efd041",
   "metadata": {},
   "source": [
    "### Verify clean up\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "71fb5195-ca41-4005-af58-ffbd03e6748e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+ docker image list -a\n",
      "REPOSITORY              TAG       IMAGE ID       CREATED         SIZE\n",
      "rwcitek/jupyter.light   latest    bb28c4444196   5 days ago      934MB\n",
      "ubuntu                  22.04     ca2b0f26964c   3 weeks ago     77.9MB\n",
      "ubuntu                  latest    ca2b0f26964c   3 weeks ago     77.9MB\n",
      "rwcitek/ubuntu          22.04     ca2b0f26964c   3 weeks ago     77.9MB\n",
      "rwcitek/barcode-gen     latest    1e4213eb03e2   16 months ago   532MB\n",
      "+ docker container list -a\n",
      "CONTAINER ID   IMAGE                   COMMAND                  CREATED        STATUS        PORTS                      NAMES\n",
      "beaf18576a8f   rwcitek/jupyter.light   \"jupyter lab --allow…\"   10 hours ago   Up 10 hours   127.0.0.1:8888->8888/tcp   jupyter\n",
      "+ docker volume list\n",
      "DRIVER    VOLUME NAME\n",
      "+ ls --color=auto -lA\n",
      "total 16\n",
      "drwxr-xr-x 1 root root  128 Mar 20 04:42 .ipynb_checkpoints\n",
      "-rw-r--r-- 1 1000 1000  692 Mar 20 04:38 Dockerfile\n",
      "-rw-r--r-- 1 1000 1000 8214 Mar 20 14:09 image.data-only.ipynb\n"
     ]
    }
   ],
   "source": [
    "docker image list -a\n",
    "docker container list -a\n",
    "docker volume list\n",
    "ls -lA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5003fc11-3770-42fb-8869-aadd4b998f39",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
